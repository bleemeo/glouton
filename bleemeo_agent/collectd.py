import logging
import os
import re
import shlex
import subprocess

import bleemeo_agent.util


BASE_COLLECTD_CONFIG = """# Configuration generated by Bleemeo-agent.
# do NOT modify, it will be overwrite on next agent start.
"""

APACHE_COLLECTD_CONFIG = """
LoadPlugin apache
<Plugin apache>
    <Instance "bleemeo-%(instance)s">
        URL "http://%(address)s:%(port)s/server-status?auto"
    </Instance>
</Plugin>
"""

BIND_COLLECTD_CONFIG = """
LoadPlugin bind
<Plugin bind>
    URL "http://%(address)s:8053"
    ParseTime       false
    OpCodes         true
    QTypes          true

    ServerStats     true
    ZoneMaintStats  true
    ResolverStats   false
    MemoryStats     true
</Plugin>
"""

MEMCACHED_COLLECTD_CONFIG = """
LoadPlugin memcached
<Plugin memcached>
    <Instance "bleemeo-%(instance)s">
        Host "%(address)s"
        Port "%(port)s"
    </Instance>
</Plugin>
"""

MYSQL_COLLECTD_CONFIG = """
LoadPlugin mysql
<Plugin mysql>
    <Database "bleemeo-%(instance)s">
        Host "%(address)s"
        User "%(user)s"
        Password "%(password)s"
        ConnectTimeout 2
    </Database>
</Plugin>
"""

NGINX_COLLECTD_CONFIG = """
LoadPlugin nginx
<Plugin nginx>
    URL "http://%(address)s:%(port)s/nginx_status"
</Plugin>
"""

NTPD_COLLECTD_CONFIG = """
LoadPlugin ntpd
<Plugin ntpd>
    Host "%(address)s"
    Port "%(port)s"
</Plugin>
"""

OPENLDAP_COLLECTD_CONFIG = """
LoadPlugin openldap
<Plugin openldap>
    <Instance "bleemeo-%(instance)s">
        URL "ldap://%(address)s/"
    </Instance>
</Plugin>
"""

POSTGRESQL_COMMON_COLLECTD_CONFIG = r"""
LoadPlugin postgresql
<Plugin postgresql>
    <Query "bleemeo-transactions">
        Statement "SELECT sum(xact_commit) xact_commit, \
                sum(xact_rollback) xact_rollback \
                FROM pg_stat_database;"
        <Result>
            Type "pg_xact"
            InstancePrefix "commit"
            ValuesFrom "xact_commit"
        </Result>
        <Result>
            Type "pg_xact"
            InstancePrefix "rollback"
            ValuesFrom "xact_rollback"
        </Result>
    </Query>
</Plugin>
"""

POSTGRESQL_COLLECTD_CONFIG = r"""
<Plugin postgresql>
    <Database "postgres">
        Host "%(address)s"
        Port "%(port)s"
        User "%(user)s"
        Password "%(password)s"
        SSLMode "prefer"
        Query "bleemeo-transactions"
        Instance "bleemeo-%(instance)s"
    </Database>
</Plugin>
"""

REDIS_COLLECTD_CONFIG = """
LoadPlugin redis
<Plugin redis>
    <Node "bleemeo-%(instance)s">
        Host "%(address)s"
        Port "%(port)s"
        Timeout 2000
    </Node>
</Plugin>
"""

VARNISH_COLLECTD_CONFIG = """
LoadPlugin varnish
<Plugin "varnish">
    <Instance "">
    </Instance>
</Plugin>
"""

# https://collectd.org/wiki/index.php/Naming_schema
# carbon output change "/" in ".".
# Example of metic name:
# cpu.percent-idle
# df-var-lib.df_complex-free
# disk-sda.disk_octets.read
collectd_regex = re.compile(
    r'(?P<plugin>[^-.]+)(-(?P<plugin_instance>[^.]+))?\.'
    r'(?P<type>[^.-]+)([.-](?P<type_instance>.+))?')


class Collectd:

    def __init__(self, graphite_server):
        self.bind_instance = None
        self.nginx_instance = None

        self.core = graphite_server.core
        self.graphite_server = graphite_server

    def update_discovery(self):
        try:
            self._write_config()
        except:
            logging.warning(
                'Failed to write collectd configuration. '
                'Continuing with current configuration')
            logging.debug('exception is:', exc_info=True)

    def _write_config(self):
        collectd_config = self._get_collectd_config()

        collectd_config_path = self.core.config.get(
            'collectd.config_file',
            '/etc/collectd/collectd.conf.d/bleemeo-generated.conf'
        )

        if os.path.exists(collectd_config_path):
            with open(collectd_config_path) as fd:
                current_content = fd.read()

            if collectd_config == current_content:
                logging.debug('collectd already configured')
                return

        if (collectd_config == BASE_COLLECTD_CONFIG
                and not os.path.exists(collectd_config_path)):
            logging.debug(
                'collectd generated config would be empty, skip writting it'
            )
            return

        # Don't simply use open. This file must have limited permission
        # since it may contains password
        open_flags = os.O_WRONLY | os.O_CREAT | os.O_TRUNC
        fileno = os.open(collectd_config_path, open_flags, 0o600)
        with os.fdopen(fileno, 'w') as fd:
            fd.write(collectd_config)

        self._restart_collectd()

    def _get_collectd_config(self):  # noqa
        has_postgres = False
        collectd_config = BASE_COLLECTD_CONFIG

        sorted_services = sorted(
            self.core.services.keys(),
            # In couple (service_name, instance) replace instance by an empty
            # string if it's None. Python 3 can not compare None and str.
            key=lambda x: (x[0], x[1] or ""),
        )
        services_type_seen = set()
        for key in sorted_services:
            (service_name, instance) = key

            service_info = self.core.services[key].copy()
            service_info['instance'] = instance
            if service_name == 'apache':
                collectd_config += APACHE_COLLECTD_CONFIG % service_info
            if service_name == 'bind' and 'bind' not in services_type_seen:
                collectd_config += BIND_COLLECTD_CONFIG % service_info
                self.bind_instance = instance
            if service_name == 'memcached':
                collectd_config += MEMCACHED_COLLECTD_CONFIG % service_info
            if (service_name == 'mysql'
                    and service_info.get('password') is not None):
                collectd_config += MYSQL_COLLECTD_CONFIG % service_info
            if service_name == 'nginx' and 'nginx' not in services_type_seen:
                collectd_config += NGINX_COLLECTD_CONFIG % service_info
                self.nginx_instance = instance
            if service_name == 'ntp':
                collectd_config += NTPD_COLLECTD_CONFIG % service_info
            if service_name == 'openldap':
                collectd_config += OPENLDAP_COLLECTD_CONFIG % service_info
            if (service_name == 'postgresql'
                    and service_info.get('password') is not None):
                if not has_postgres:
                    collectd_config += POSTGRESQL_COMMON_COLLECTD_CONFIG
                    has_postgres = True
                collectd_config += POSTGRESQL_COLLECTD_CONFIG % service_info
            if service_name == 'redis':
                collectd_config += REDIS_COLLECTD_CONFIG % service_info
            # collectd could only monitor varnish on same host as collectd
            if (service_name == 'varnish'
                    and instance is None
                    and self.core.config.get('collectd.docker_name') is None):
                collectd_config += VARNISH_COLLECTD_CONFIG % service_info

            services_type_seen.add(service_name)

        return collectd_config

    def _restart_collectd(self):
        restart_cmd = self.core.config.get(
            'collectd.restart_command',
            'sudo --non-interactive service collectd restart')
        collectd_container = self.core.config.get('collectd.docker_name')
        if collectd_container is not None:
            bleemeo_agent.util.docker_restart(
                self.core.docker_client, collectd_container
            )
        else:
            try:
                output = subprocess.check_output(
                    shlex.split(restart_cmd),
                    stderr=subprocess.STDOUT,
                )
                return_code = 0
            except subprocess.CalledProcessError as exception:
                output = exception.output
                return_code = exception.returncode

            if return_code != 0:
                logging.info(
                    'Failed to restart collectd after reconfiguration : %s',
                    output
                )
            else:
                logging.debug(
                    'collectd reconfigured and restarted : %s', output)

    def emit_metric(  # noqa
            self, name, timestamp, value, computed_metrics_pending):
        """ Rename a metric and pass it to core

            If the metric is used to compute a derrived metric, add it to
            computed_metrics_pending.

            Nothing is emitted if metric is unknown
        """
        # the first component is the hostname
        name = name.split('.', 1)[1]
        match = collectd_regex.match(name)
        if match is None:
            return
        match_dict = match.groupdict()

        item = None
        service = None

        if match_dict['plugin'] == 'cpu':
            name = 'cpu_%s' % match_dict['type_instance']
            if name == 'cpu_idle':
                self.core.emit_metric({
                    'measurement': 'cpu_used',
                    'time': timestamp,
                    'value': 100 - value,
                })
            computed_metrics_pending.add(('cpu_other', None, timestamp))
        elif match_dict['type'] == 'df_complex':
            name = 'disk_%s' % match_dict['type_instance']
            path = match_dict['plugin_instance']
            if path == 'root':
                path = '/'
            else:
                path = '/' + path.replace('-', '/')
            path = self.graphite_server._disk_path_rename(path)
            if path is None:
                # this partition is ignored
                return

            item = path
            computed_metrics_pending.add(('disk_total', item, timestamp))
        elif match_dict['plugin'] == 'disk':
            if match_dict['type_instance'] == 'io_time':
                name = 'io_time'
            elif match_dict['type_instance'] == 'weighted_io_time':
                name = 'io_time_weighted'
            elif match_dict['type'] == 'pending_operations':
                name = 'io_pending_operations'
            else:
                kind_name = {
                    'disk_merged': '_merged',
                    'disk_octets': '_bytes',
                    'disk_ops': 's',  # will become readS and writeS
                    'disk_time': '_time',
                }[match_dict['type']]
                name = 'io_%s%s' % (match_dict['type_instance'], kind_name)

            item = match_dict['plugin_instance']
            if self.graphite_server._ignored_disk(item):
                return
            if name == 'io_time':
                self.core.emit_metric({
                    'measurement': 'io_utilization',
                    # io_time is a number of ms spent doing IO (per seconds)
                    # utilization is 100% when we spent 1000ms during one
                    # second
                    'value': value / 1000. * 100.,
                    'time': timestamp,
                    'item': item,
                })
        elif match_dict['plugin'] == 'interface':
            kind_name = {
                'if_errors': 'err',
                'if_octets': 'bytes',
                'if_packets': 'packets',
            }[match_dict['type']]

            if match_dict['type_instance'] == 'rx':
                direction = 'recv'
            else:
                direction = 'sent'

            item = match_dict['plugin_instance']
            if self.graphite_server.network_interface_blacklist(item):
                return

            # Special cases:
            # * if it's some error, we use "in" and "out"
            # * for bytes, we need to convert it to bits
            if kind_name == 'err':
                direction = (
                    direction
                    .replace('recv', 'in')
                    .replace('sent', 'out')
                )
            elif kind_name == 'bytes':
                kind_name = 'bits'
                value = value * 8

            name = 'net_%s_%s' % (kind_name, direction)
        elif match_dict['plugin'] == 'load':
            duration = {
                'longterm': 15,
                'midterm': 5,
                'shortterm': 1,
            }[match_dict['type_instance']]
            name = 'system_load%s' % duration
        elif match_dict['plugin'] == 'memory':
            name = 'mem_%s' % match_dict['type_instance']
            computed_metrics_pending.add(('mem_total', None, timestamp))
        elif (match_dict['plugin'] == 'processes'
                and match_dict['type'] == 'fork_rate'):
            name = 'process_fork_rate'
        elif (match_dict['plugin'] == 'processes'
                and match_dict['type'] == 'ps_state'):
            name = 'process_status_%s' % match_dict['type_instance']
            computed_metrics_pending.add(
                ('process_total', None, timestamp))
        elif match_dict['plugin'] == 'swap' and match_dict['type'] == 'swap':
            name = 'swap_%s' % match_dict['type_instance']
            computed_metrics_pending.add(('swap_total', None, timestamp))
        elif (match_dict['plugin'] == 'swap'
                and match_dict['type'] == 'swap_io'):
            name = 'swap_%s' % match_dict['type_instance']
        elif match_dict['plugin'] == 'users':
            name = 'users_logged'
        elif (match_dict['plugin'] == 'apache'
                and match_dict['plugin_instance'].startswith('bleemeo-')):
            name = match_dict['type']
            if match_dict['type_instance']:
                name += '_' + match_dict['type_instance']

            item = match_dict['plugin_instance'].replace('bleemeo-', '')
            if item == 'None':
                item = None
            service = 'apache'
        elif (match_dict['plugin'] == 'mysql'
                and match_dict['plugin_instance'].startswith('bleemeo-')):
            name = match_dict['type']
            if match_dict['type_instance']:
                name += '_' + match_dict['type_instance']

            if not name.startswith('mysql_'):
                name = 'mysql_' + name

            name = name.replace('-', '_')

            item = match_dict['plugin_instance'].replace('bleemeo-', '')
            if item == 'None':
                item = None

            service = 'mysql'
        elif (match_dict['plugin'] == 'postgresql'
                and match_dict['plugin_instance'].startswith('bleemeo-')):
            name = 'postgresql_' + match_dict['type_instance']
            item = match_dict['plugin_instance'].replace('bleemeo-', '')
            if item == 'None':
                item = None
            service = 'postgresql'
        elif (match_dict['plugin'] == 'redis'
                and match_dict['plugin_instance'].startswith('bleemeo-')):
            name = match_dict['type']
            if match_dict['type_instance']:
                name += '_' + match_dict['type_instance']

            name = 'redis_' + name

            item = match_dict['plugin_instance'].replace('bleemeo-', '')
            if item == 'None':
                item = None

            service = 'redis'
        elif (match_dict['plugin'] == 'memcached'
                and match_dict['plugin_instance'].startswith('bleemeo-')):
            name = match_dict['type']
            if match_dict['type_instance']:
                name += '_' + match_dict['type_instance']

            if not name.startswith('memcached_'):
                name = 'memcached_' + name

            name = name.replace('.', '_')

            item = match_dict['plugin_instance'].replace('bleemeo-', '')
            if item == 'None':
                item = None

            service = 'memcached'
        elif (match_dict['plugin'] == 'ntpd'
                and match_dict['type'] == 'time_offset'
                and match_dict['type_instance'] == 'loop'):
            name = 'ntp_time_offset'
            service = 'ntp'
            # value is in ms. Convert it to second
            value = value / 1000.
        elif match_dict['plugin'] == 'bind':
            service = 'bind'
            item = self.bind_instance
            if (match_dict['plugin_instance'] == 'global-qtypes'
                    and match_dict['type'] == 'dns_qtype'):
                name = 'bind_query_%s' % match_dict['type_instance']
            if (match_dict['plugin_instance'] == 'global-opcodes'
                    and match_dict['type'] == 'dns_opcode'
                    and match_dict['type_instance'] == 'QUERY'):
                name = 'bind_requests'
            else:
                return
        elif match_dict['plugin'] == 'nginx':
            service = 'nginx'
            name = match_dict['type'].replace('-', '_')
            item = self.nginx_instance
            if match_dict['type_instance']:
                name += '_' + match_dict['type_instance']
            if not name.startswith('nginx_'):
                name = 'nginx_' + name
        elif (match_dict['plugin'] == 'openldap'
                and match_dict['plugin_instance'].startswith('bleemeo-')):
            service = 'openldap'
            item = match_dict['plugin_instance'].replace('bleemeo-', '')
            if item == 'None':
                item = None
            name = 'openldap_' + match_dict['type']

            if match_dict['type_instance']:
                name = name + '_' + match_dict['type_instance']

            name = name.replace('-', '_')

            if name == 'openldap_total_connections':
                name = 'openldap_connections_rate'
            elif name == 'openldap_current_connections':
                name = 'openldap_connections'
            elif '_derive_statistics_' in name:
                name = name.replace('_derive_statistics_', '_')
            elif '_derive_waiters_' in name:
                name = name.replace('_derive_waiters_', '_waiters_')
            elif '_threads_threads_' in name:
                name = name.replace('_threads_threads_', '_threads_')

        elif match_dict['plugin'] == 'varnish':
            service = 'varnish'
            if match_dict['plugin_instance'].endswith('connections'):
                name = 'connections_' + match_dict['type_instance']
            elif match_dict['plugin_instance'].endswith('backend'):
                name = (
                    'backend_' +
                    match_dict['type'] +
                    '_' +
                    match_dict['type_instance']
                )
                if 'backend_backends' in name:
                    name = name.replace('backend_backends', 'backend')
            elif match_dict['plugin_instance'].endswith('cache'):
                name = 'cache_' + match_dict['type_instance']
            elif match_dict['plugin_instance'].endswith('shm'):
                name = 'shm_' + match_dict['type_instance']
            else:
                return

            name = 'varnish_' + name.replace('-', '_')

            if name == 'varnish_connections_received':
                name = 'varnish_requests'
            elif name == 'varnish_backend_htt_requests':
                name = 'varnish_backend_requests'
        else:
            return

        metric = {
            'measurement': name,
            'time': timestamp,
            'value': value,
        }
        if service is not None:
            metric['service'] = service
        if item is not None:
            metric['item'] = item

        self.core.emit_metric(metric)
